{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuzFwRGBvt8i",
    "outputId": "10264bee-8112-448f-8785-f6d7a1a767cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chess==1.11.2 (from -r requirements.txt (line 1))\n",
      "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
      "     ---------------------------------------- 0.0/6.1 MB ? eta -:--:--\n",
      "     ------------------------------------- -- 5.8/6.1 MB 32.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.1/6.1 MB 28.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\users\\jerry\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 2)) (0.4.6)\n",
      "Collecting exceptiongroup==1.3.1 (from -r requirements.txt (line 3))\n",
      "  Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting filelock==3.20.3 (from -r requirements.txt (line 4))\n",
      "  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec==2026.1.0 (from -r requirements.txt (line 5))\n",
      "  Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting iniconfig==2.3.0 (from -r requirements.txt (line 6))\n",
      "  Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in c:\\users\\jerry\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 7)) (3.1.6)\n",
      "Collecting MarkupSafe==3.0.3 (from -r requirements.txt (line 8))\n",
      "  Downloading markupsafe-3.0.3-cp310-cp310-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting mpmath==1.3.0 (from -r requirements.txt (line 9))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting networkx==3.4.2 (from -r requirements.txt (line 10))\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting numpy==2.2.6 (from -r requirements.txt (line 11))\n",
      "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: packaging==25.0 in c:\\users\\jerry\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 12)) (25.0)\n",
      "Collecting pluggy==1.6.0 (from -r requirements.txt (line 13))\n",
      "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting Pygments==2.19.2 (from -r requirements.txt (line 14))\n",
      "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pytest==9.0.2 (from -r requirements.txt (line 15))\n",
      "  Downloading pytest-9.0.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting python-chess==1.999 (from -r requirements.txt (line 16))\n",
      "  Using cached python_chess-1.999-py3-none-any.whl.metadata (776 bytes)\n",
      "Collecting sympy==1.14.0 (from -r requirements.txt (line 17))\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tomli==2.4.0 (from -r requirements.txt (line 18))\n",
      "  Downloading tomli-2.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting torch==2.9.1 (from -r requirements.txt (line 19))\n",
      "  Downloading torch-2.9.1-cp310-cp310-win_amd64.whl.metadata (30 kB)\n",
      "Collecting typing_extensions==4.15.0 (from -r requirements.txt (line 20))\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
      "Downloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
      "Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading markupsafe-3.0.3-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 17.1 MB/s eta 0:00:00\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 31.1 MB/s eta 0:00:00\n",
      "Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 8.9/12.9 MB 42.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 36.8 MB/s eta 0:00:00\n",
      "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 31.1 MB/s eta 0:00:00\n",
      "Downloading pytest-9.0.2-py3-none-any.whl (374 kB)\n",
      "Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.3/6.3 MB 32.1 MB/s eta 0:00:00\n",
      "Downloading tomli-2.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading torch-2.9.1-cp310-cp310-win_amd64.whl (111.0 MB)\n",
      "   ---------------------------------------- 0.0/111.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 6.6/111.0 MB 33.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 13.6/111.0 MB 32.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 19.7/111.0 MB 31.9 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 26.5/111.0 MB 31.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 33.0/111.0 MB 32.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 40.1/111.0 MB 31.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 48.0/111.0 MB 32.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 54.5/111.0 MB 32.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 62.1/111.0 MB 32.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 69.5/111.0 MB 32.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 75.5/111.0 MB 32.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 82.8/111.0 MB 32.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 90.4/111.0 MB 33.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 97.5/111.0 MB 32.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 105.4/111.0 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/111.0 MB 33.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 111.0/111.0 MB 31.1 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Building wheels for collected packages: chess\n",
      "  Building wheel for chess (setup.py): started\n",
      "  Building wheel for chess (setup.py): finished with status 'done'\n",
      "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147813 sha256=dee50b4c65cf1301e3991b60cc7e92a51422c4644c9606ef54ff56cbf83a7537\n",
      "  Stored in directory: c:\\users\\jerry\\appdata\\local\\pip\\cache\\wheels\\7a\\79\\8e\\0d6e404db9f1e82af2e40b49161d6acab485d75dfb0470ac08\n",
      "Successfully built chess\n",
      "Installing collected packages: mpmath, typing_extensions, tomli, sympy, Pygments, pluggy, numpy, networkx, MarkupSafe, iniconfig, fsspec, filelock, chess, python-chess, exceptiongroup, torch, pytest\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: tomli\n",
      "    Found existing installation: tomli 2.0.1\n",
      "    Uninstalling tomli-2.0.1:\n",
      "      Successfully uninstalled tomli-2.0.1\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.16.1\n",
      "    Uninstalling Pygments-2.16.1:\n",
      "      Successfully uninstalled Pygments-2.16.1\n",
      "  Attempting uninstall: pluggy\n",
      "    Found existing installation: pluggy 1.5.0\n",
      "    Uninstalling pluggy-1.5.0:\n",
      "      Successfully uninstalled pluggy-1.5.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.0\n",
      "    Uninstalling numpy-1.26.0:\n",
      "      Successfully uninstalled numpy-1.26.0\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "  Attempting uninstall: iniconfig\n",
      "    Found existing installation: iniconfig 2.0.0\n",
      "    Uninstalling iniconfig-2.0.0:\n",
      "      Successfully uninstalled iniconfig-2.0.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.8.0\n",
      "    Uninstalling filelock-3.8.0:\n",
      "      Successfully uninstalled filelock-3.8.0\n",
      "  Attempting uninstall: chess\n",
      "    Found existing installation: chess 1.11.1\n",
      "    Uninstalling chess-1.11.1:\n",
      "      Successfully uninstalled chess-1.11.1\n",
      "  Attempting uninstall: exceptiongroup\n",
      "    Found existing installation: exceptiongroup 1.2.2\n",
      "    Uninstalling exceptiongroup-1.2.2:\n",
      "      Successfully uninstalled exceptiongroup-1.2.2\n",
      "  Attempting uninstall: pytest\n",
      "    Found existing installation: pytest 8.3.3\n",
      "    Uninstalling pytest-8.3.3:\n",
      "      Successfully uninstalled pytest-8.3.3\n",
      "Successfully installed MarkupSafe-3.0.3 Pygments-2.19.2 chess-1.11.2 exceptiongroup-1.3.1 filelock-3.20.3 fsspec-2026.1.0 iniconfig-2.3.0 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 pluggy-1.6.0 pytest-9.0.2 python-chess-1.999 sympy-1.14.0 tomli-2.4.0 torch-2.9.1 typing_extensions-4.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\jerry\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~arkupsafe'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.17.1 requires keras>=3.2.0, but you have keras 2.10.0 which is incompatible.\n",
      "tensorflow-intel 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.2.6 which is incompatible.\n",
      "tensorflow-intel 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
      "tensorflow-intel 2.17.1 requires tensorboard<2.18,>=2.17, but you have tensorboard 2.10.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZb0FoECv-r3"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "QKX9k-9Mx60R",
    "outputId": "7f392ff9-3c2a-434e-c9c4-b13928e6e6ae"
   },
   "outputs": [],
   "source": [
    "\n",
    "import chess\n",
    "import numpy as np\n",
    "\n",
    "class ChessEnv:\n",
    "    def __init__(self):\n",
    "        self.board = chess.Board()\n",
    "\n",
    "    def copy(self):\n",
    "        env = ChessEnv()\n",
    "        env.board = self.board.copy(stack = True)\n",
    "        return env\n",
    "    def legal_moves(self):\n",
    "        return list(self.board.legal_moves)\n",
    "\n",
    "    def push(self,move):\n",
    "        self.board.push(move)\n",
    "\n",
    "    def is_terminal(self):\n",
    "        return self.board.is_game_over()\n",
    "\n",
    "    def result(self):\n",
    "        if not self.board.is_game_over():\n",
    "            return None\n",
    "        outcome = self.board.outcome()\n",
    "        #print(f'outcome is {outcome} and outcome winner is {outcome.winner}')\n",
    "        if outcome.winner is None:\n",
    "            #print(f'returning 0')\n",
    "            return 0\n",
    "\n",
    "        # in python chess true refers to white false refers to black\n",
    "        return 1 if outcome.winner else -1\n",
    "\n",
    "    # encodes current position from perspective of current player\n",
    "    def encode(self):\n",
    "        '''\n",
    "        AlphaZero style encoding\n",
    "\n",
    "        Returns:\n",
    "            planes: np.ndarray of shape (21, 8 ,8)\n",
    "\n",
    "        :param self: Description\n",
    "        '''\n",
    "\n",
    "        planes = np.zeros((21,8,8), dtype = np.float32)\n",
    "\n",
    "        # Piece planes\n",
    "        # Planes 0-5: p1 pieces\n",
    "        # Planes 6-11: p2 pieces\n",
    "        # Piece type enums directly correspond to plane\n",
    "        for square, piece in self.board.piece_map().items():\n",
    "            row = 7-chess.square_rank(square)\n",
    "            col = chess.square_file(square)\n",
    "\n",
    "            if piece.color == self.board.turn:\n",
    "                planes[piece.piece_type-1, row, col]=1.0\n",
    "            else:\n",
    "                planes[piece.piece_type+5,row,col]=1.0\n",
    "\n",
    "        # repetition planes 12-13\n",
    "        # plane 12 represents repeated once\n",
    "        # plane 13 represents repeated twice\n",
    "\n",
    "        if self.board.is_repetition(1):\n",
    "            planes[12, :, :] = 1.0\n",
    "        if self.board.is_repetition(2):\n",
    "            planes[13, :, :] = 1.0\n",
    "\n",
    "\n",
    "        # plane 14: all 1s if its white\n",
    "        if self.board.turn:\n",
    "            planes[14,:,:]=1.0\n",
    "\n",
    "        # plane 15: move count normalized by /100\n",
    "        planes[15,:,:] = min(1,self.board.fullmove_number/100)\n",
    "\n",
    "        # plane 16-17: current player has castling rights\n",
    "        if self.board.has_kingside_castling_rights(self.board.turn):\n",
    "            planes[16,:,:]=1.0\n",
    "        if self.board.has_queenside_castling_rights(self.board.turn):\n",
    "            planes[17,:,:]=1.0\n",
    "\n",
    "        # plane 18-19: opponent has castling rights\n",
    "        opponent = not self.board.turn\n",
    "        if self.board.has_kingside_castling_rights(opponent):\n",
    "            planes[18,:,:]=1.0\n",
    "        if self.board.has_queenside_castling_rights(opponent):\n",
    "            planes[19,:,:]=1.0\n",
    "\n",
    "        # plane 20: halfmove clock normalized by /100\n",
    "\n",
    "        planes[20,:,:]= min(1,self.board.halfmove_clock/100)\n",
    "\n",
    "        return planes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BvrGUPGwx9Xo"
   },
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy as np\n",
    "import config\n",
    "\n",
    "# Directions for sliding pieces\n",
    "\n",
    "PROMOTION_PIECES = [chess.ROOK, chess.KNIGHT, chess.BISHOP]\n",
    "DIRS = [\n",
    "    (1,0), (-1,0), (0,1), (0,-1),\n",
    "    (1,1), (1,-1), (-1,1), (-1,-1)\n",
    "]\n",
    "\n",
    "KNIGHT_DIRS = [\n",
    "    (2,1), (2,-1), (-2,1), (-2,-1),\n",
    "    (1,2), (1,-2), (-1,2), (-1,-2)\n",
    "]\n",
    "\n",
    "def sign(x):\n",
    "    if x>0:\n",
    "        return 1\n",
    "    elif x<0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "def move_to_index(move: chess.Move) -> int:\n",
    "    # maps a chess move to index in [0,4671]\n",
    "    from_sq = move.from_square\n",
    "    to_sq = move.to_square\n",
    "\n",
    "    fx,fy = chess.square_file(from_sq), chess.square_rank(from_sq)\n",
    "    tx,ty = chess.square_file(to_sq), chess.square_rank(to_sq)\n",
    "\n",
    "    dx = tx-fx\n",
    "    dy = ty-fy\n",
    "\n",
    "    if move.promotion and move.promotion != chess.QUEEN:\n",
    "        direction = dx+1\n",
    "        promo_idx = PROMOTION_PIECES.index(move.promotion)\n",
    "        plane = 64+direction*3+promo_idx\n",
    "    elif (dx,dy) in KNIGHT_DIRS:\n",
    "        plane = 56 + KNIGHT_DIRS.index((dx,dy))\n",
    "    else:\n",
    "        step_dx = 0 if dx==0 else dx//abs(dx)\n",
    "        step_dy = 0 if dy==0 else dy//abs(dy)\n",
    "\n",
    "        direction = DIRS.index((step_dx,step_dy))\n",
    "        dist = max(abs(dx),abs(dy))\n",
    "        plane = direction*7 + (dist-1)\n",
    "\n",
    "    return from_sq * 73 + plane\n",
    "\n",
    "def index_to_move(index: int, board: chess.Board) -> chess.Move:\n",
    "    from_sq = index // 73\n",
    "    plane = index %73\n",
    "\n",
    "    #print(f'plane is {plane} square is {from_sq} which is {chess.square_name(from_sq)}')\n",
    "\n",
    "    piece = board.piece_at(from_sq)\n",
    "    if piece is None:\n",
    "        #print(f'No piece at from_sq {chess.square_name(from_sq)}')\n",
    "        return None\n",
    "    #print(f'current piece at from_sq is {piece} color is {(\"W\" if piece and piece.color==chess.WHITE else \"B\" if piece else \"None\")}')\n",
    "    fx,fy = chess.square_file(from_sq), chess.square_rank(from_sq)\n",
    "\n",
    "    if plane>=64:\n",
    "        direction = (plane-64)//3\n",
    "        promo_idx = (plane-64)%3\n",
    "        #print(f'underpromotion direction is {direction} promo idx is {promo_idx} which corresponds to {PROMOTION_PIECES[promo_idx]}')\n",
    "        dx = direction-1\n",
    "        dy = 1 if piece.color == chess.WHITE else -1\n",
    "\n",
    "        to_sq = chess.square(fx+dx,fy + dy)\n",
    "        #print(f'dx is {dx} dy is {dy} to_sq is {fx+dx},{fy + dy} which is {chess.square_name(chess.square(fx+dx,fy + dy))}')\n",
    "        promotion = PROMOTION_PIECES[promo_idx]\n",
    "        if fx+dx<0 or fx+dx>7 or fy+dy<0 or fy+dy>7 or piece is None or piece.piece_type != 1:\n",
    "            #print(f'out of bounds or invalid')\n",
    "            return None\n",
    "        return chess.Move(from_sq, to_sq, promotion=promotion)\n",
    "    elif plane>=56:\n",
    "        knight_idx = plane-56\n",
    "        dx,dy = KNIGHT_DIRS[knight_idx]\n",
    "        to_sq = chess.square(fx+dx,fy+dy)\n",
    "        if fx+dx<0 or fx+dx>7 or fy+dy<0 or fy+dy>7:\n",
    "            return None\n",
    "        return chess.Move(from_sq,to_sq)\n",
    "    else:\n",
    "        direction = plane//7\n",
    "        dist = (plane%7)+1\n",
    "\n",
    "        step_dx,step_dy = DIRS[direction]\n",
    "        dx = step_dx * dist\n",
    "        dy = step_dy * dist\n",
    "\n",
    "        #print(f'direction is {direction} which is {step_dx}, {step_dy} dist is {dist} resulting in dx {dx} dy {dy}')\n",
    "\n",
    "        to_rank = fy+dy\n",
    "        #print(f'to_rank is {to_rank} piece is {piece} piecetype is {piece.piece_type if piece else \"None\"} which corresponds to {chess.piece_name(piece.piece_type) if piece else \"None\"}')\n",
    "        if piece is not None and piece.piece_type == 1 and (to_rank==0 or to_rank==7):\n",
    "            promotion = chess.QUEEN\n",
    "        else:\n",
    "            promotion = None\n",
    "        #print(f'promotion is {promotion}')\n",
    "\n",
    "        # check if last rank and pawn move for queen promotion\n",
    "        to_sq = chess.square(fx+dx,fy+dy)\n",
    "        if fx+dx<0 or fx+dx>7 or fy+dy<0 or fy+dy>7:\n",
    "            return None\n",
    "        return chess.Move(from_sq,to_sq,promotion=promotion)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5NtW48oCyMfh"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import config\n",
    "import torch\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,env:ChessEnv, parent: \"Node\" = None, parent_move = None, prior = 0):\n",
    "        self.env = env\n",
    "        self.parent = parent\n",
    "        self.parent_move = parent_move\n",
    "\n",
    "        self.children = {}\n",
    "        self.untried_moves = env.legal_moves()\n",
    "\n",
    "        np.random.shuffle(self.untried_moves)\n",
    "\n",
    "        self.N = 0\n",
    "        self.W = 0.0\n",
    "        self.prior = prior\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.untried_moves)==0 and len(self.children)>0\n",
    "    def is_expanded(self):\n",
    "        return len(self.children)>0\n",
    "\n",
    "    '''\n",
    "    def get_ucb(self, child):\n",
    "        if child.N == 0:\n",
    "            return float('inf')\n",
    "        q_value = 1 - ((child.W/child.N)+1)/2\n",
    "        return q_value + config.UCB_C * np.sqrt(np.log(self.N) / child.N)\n",
    "    '''\n",
    "    def get_ucb(self, child):\n",
    "        if child.N == 0:\n",
    "            return float('inf')\n",
    "        return (child.W / child.N) + config.UCB_C * np.sqrt(np.log(self.N) / child.N)\n",
    "\n",
    "    def get_puct(self, child):\n",
    "        q_value = 0 if child.N==0 else 1 - ((child.W/child.N)+1)/2\n",
    "        u_value = config.PUCT_C * child.prior * (np.sqrt(self.N) / (1+child.N))\n",
    "        return q_value + u_value\n",
    "\n",
    "    def expand_random(self):\n",
    "        action = self.untried_moves[-1]\n",
    "        self.untried_moves.pop()\n",
    "\n",
    "        child_state = self.env.copy()\n",
    "        child_state.push(action)\n",
    "        child = Node(child_state, parent = self, parent_move = action)\n",
    "        self.children[action] = child\n",
    "        return child\n",
    "\n",
    "    def expand(self, model, device):\n",
    "        planes = self.env.encode()\n",
    "        x = torch.tensor(planes, dtype = torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            policy, value = model(x)\n",
    "        policy = policy.squeeze(0).cpu().numpy()\n",
    "        value = value.item()\n",
    "        legal_moves = self.env.legal_moves()\n",
    "\n",
    "        priors = []\n",
    "        total_prior = 0.0\n",
    "\n",
    "        for move in legal_moves:\n",
    "            idx = move_to_index(move)\n",
    "            priors.append(policy[idx])\n",
    "        priors = np.array(priors)\n",
    "        priors = np.maximum(priors,1e-10)\n",
    "        priors /= np.sum(priors)\n",
    "\n",
    "        for move,prior in zip(legal_moves,priors):\n",
    "            next_env = self.env.copy()\n",
    "            next_env.push(move)\n",
    "            self.children[move] = Node(next_env,parent=self,parent_move=move,prior=prior)\n",
    "        return value\n",
    "\n",
    "    def select_random(self):\n",
    "        best_child = None\n",
    "        best_ucb = -np.inf\n",
    "\n",
    "        for child_action, child in self.children.items():\n",
    "            ucb = self.get_ucb(child)\n",
    "            if ucb > best_ucb:\n",
    "                best_child = child\n",
    "                best_ucb = ucb\n",
    "        return best_child\n",
    "    def select(self):\n",
    "        best_child = None\n",
    "        best_puct = -np.inf\n",
    "        for child_action, child in self.children.items():\n",
    "            puct = self.get_puct(child)\n",
    "            if puct > best_puct:\n",
    "                best_child = child\n",
    "                best_puct = puct\n",
    "        return best_child\n",
    "\n",
    "    def simulate(self):\n",
    "        winner = self.env.result()\n",
    "\n",
    "        rollout_state = self.env.copy()\n",
    "        initial_player = 1 if self.env.board.turn else -1\n",
    "        #print(f'initial player is initally {initial_player} board is \\n {rollout_state.board}')\n",
    "\n",
    "        val = None\n",
    "\n",
    "        while True:\n",
    "            if winner is not None:\n",
    "                #print(f'simulate board is now\\n {rollout_state.board} winner is {winner}')\n",
    "                if winner==initial_player:\n",
    "                    val= 1\n",
    "                elif winner==0:\n",
    "                    val= 0\n",
    "                else:\n",
    "                    val = -1\n",
    "                #print(f'returning simulate function {val}')\n",
    "                return val\n",
    "            valid_moves=  rollout_state.legal_moves()\n",
    "            action = np.random.choice(valid_moves)\n",
    "            rollout_state.push(action)\n",
    "            winner = rollout_state.result()\n",
    "\n",
    "\n",
    "    def backpropagate(self, value):\n",
    "        self.W+=value\n",
    "        self.N+=1\n",
    "        #print(f'propagating state {self.env.board} with val {value}')\n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(value*-1)\n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self,model = None, device = 'cpu'):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        pass\n",
    "\n",
    "    def search(self,state):\n",
    "        root = Node(state)\n",
    "\n",
    "        for _ in range(config.NUM_SEARCHES):\n",
    "            node = root\n",
    "\n",
    "            while node.is_fully_expanded():\n",
    "                node = node.select_random()\n",
    "\n",
    "            val = node.env.result()\n",
    "            if val is None:\n",
    "                if node.untried_moves:\n",
    "                    node = node.expand_random()\n",
    "                    val = node.simulate()\n",
    "            else:\n",
    "                pass\n",
    "            node.backpropagate(val)\n",
    "\n",
    "        action_probs = {}\n",
    "        total = 0\n",
    "        for child_action, child in root.children.items():\n",
    "            action_probs[child_action]=child.N\n",
    "            total+=child.N\n",
    "\n",
    "        for key in action_probs:\n",
    "            action_probs[key]/=total\n",
    "\n",
    "        return action_probs\n",
    "\n",
    "\n",
    "class AlphaMCTS:\n",
    "    def __init__(self,model, device = 'cpu'):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def search(self, state:ChessEnv):\n",
    "        root = Node(state)\n",
    "\n",
    "        # expand once to get priors\n",
    "\n",
    "        value = root.expand(self.model,self.device)\n",
    "\n",
    "        # dirichlet noise\n",
    "        legal_moves = list(root.children.keys())\n",
    "        noise = np.random.dirichlet([config.DIRICHLET_ALPHA]*len(legal_moves))\n",
    "\n",
    "        for move,n in zip(legal_moves,noise):\n",
    "            child = root.children[move]\n",
    "            child.prior = (1-config.DIRICHLET_EPSILON)*child.prior+config.DIRICHLET_EPSILON*n\n",
    "\n",
    "        root.backpropagate(value)\n",
    "\n",
    "        for _ in range(config.NUM_SEARCHES-1):\n",
    "            node = root\n",
    "\n",
    "            while node.is_expanded() and not node.env.is_terminal():\n",
    "                node = node.select()\n",
    "            value = node.env.result()\n",
    "            if value is None:\n",
    "                value = node.expand(self.model,self.device)\n",
    "            node.backpropagate(value)\n",
    "        action_probs = {}\n",
    "        total_visits = sum([child.N for child in root.children.values()])\n",
    "\n",
    "        for child_action, child in root.children.items():\n",
    "            action_probs[child_action] = 0 if total_visits==0 else child.N/total_visits\n",
    "\n",
    "        return action_probs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "u41-w--cyYKW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=None, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        outchannels = out_channels or config.NUM_CHANNELS\n",
    "        self.conv = nn.Conv2d(in_channels,out_channels, kernel_size=kernel_size, padding = padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,channels = None):\n",
    "        super().__init__()\n",
    "        channels = channels or config.NUM_CHANNELS\n",
    "        self.conv1 = nn.Conv2d(channels,channels,3,padding=1,bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels,channels,3,padding=1,bias=False)\n",
    "        self.bn2=nn.BatchNorm2d(channels)\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out+=residual\n",
    "        return F.relu(out)\n",
    "\n",
    "class PolicyHead(nn.Module):\n",
    "    def __init__(self,in_channels = None, action_size = None):\n",
    "        super().__init__()\n",
    "        in_channels = in_channels or config.NUM_CHANNELS\n",
    "        action_size = action_size or config.ACTION_SIZE\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, config.POLICY_HEAD_CHANNELS, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(config.POLICY_HEAD_CHANNELS)\n",
    "        self.fc = nn.Linear(config.POLICY_HEAD_CHANNELS*8*8, action_size)\n",
    "\n",
    "    def forward(self,x,legal_mask = None):\n",
    "        x = F.relu(self.bn(self.conv(x)))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        if legal_mask is not None:\n",
    "            x = x.masked_fill(legal_mask==0, float('-inf'))\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "class ValueHead(nn.Module):\n",
    "    def __init__(self,in_channels = None):\n",
    "        super().__init__()\n",
    "        in_channels = in_channels or config.NUM_CHANNELS\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, config.VALUE_HEAD_CHANNELS, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(config.VALUE_HEAD_CHANNELS)\n",
    "        self.fc1 = nn.Linear(config.VALUE_HEAD_CHANNELS*8*8, 256)\n",
    "        self.fc2 = nn.Linear(256,1)\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.bn(self.conv(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "class ChessModel(nn.Module):\n",
    "    def __init__(self, in_channels = 21, num_res_blocks = None, action_size = None):\n",
    "        super().__init__()\n",
    "        num_res_blocks = num_res_blocks or config.NUM_RES_BLOCKS\n",
    "        action_size = action_size or config.ACTION_SIZE\n",
    "\n",
    "        self.conv_block = ConvBlock(in_channels, config.NUM_CHANNELS)\n",
    "\n",
    "        self.res_blocks = nn.ModuleList(\n",
    "            [ResBlock(config.NUM_CHANNELS) for _ in range(num_res_blocks)]\n",
    "        )\n",
    "\n",
    "        self.policy_head = PolicyHead(config.NUM_CHANNELS, action_size)\n",
    "        self.value_head = ValueHead(config.NUM_CHANNELS)\n",
    "\n",
    "    def forward(self,x, legal_mask = None):\n",
    "        x = self.conv_block(x)\n",
    "        for res_block in self.res_blocks:\n",
    "            x = res_block(x)\n",
    "\n",
    "        policy = self.policy_head(x, legal_mask)\n",
    "        value = self.value_head(x)\n",
    "\n",
    "        return policy, value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wHRjKvRQykg3"
   },
   "outputs": [],
   "source": [
    "class AlphaZero:\n",
    "    def __init__(self,model,optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.mcts = AlphaMCTS(model)\n",
    "        self.device = next(model.parameters()).device\n",
    "\n",
    "    @staticmethod\n",
    "    def pi_to_vector(pi_dict):\n",
    "        target = np.zeros(config.ACTION_SIZE,dtype=np.float32)\n",
    "        for move, prob in pi_dict.items():\n",
    "            index = move_to_index(move)\n",
    "            target[index]=prob\n",
    "        return target\n",
    "\n",
    "    def selfPlay(self):\n",
    "        memory = []\n",
    "        env = ChessEnv()\n",
    "        move_count = 0\n",
    "\n",
    "        while not env.is_terminal():\n",
    "            # mcts\n",
    "            pi = self.mcts.search(env)\n",
    "            memory.append([env.encode(),self.pi_to_vector(pi)])\n",
    "\n",
    "            # temperature\n",
    "            tau = 1 if move_count<15 else 0\n",
    "\n",
    "            if tau==0:\n",
    "                action = max(pi, key = pi.get)\n",
    "            else:\n",
    "                moves = list(pi.keys())\n",
    "                probs = np.array([pi[m] for m in moves])\n",
    "                probs = probs / probs.sum()\n",
    "                action = np.random.choice(moves, p = probs)\n",
    "\n",
    "            env.push(action)\n",
    "            move_count+=1\n",
    "        z = env.result()\n",
    "\n",
    "        for entry in memory:\n",
    "            entry.append(z)\n",
    "            z = -z\n",
    "        return memory\n",
    "    '''\n",
    "    def train(self,memory):\n",
    "        np.random.shuffle(memory)\n",
    "        for startInd in range(0,len(memory),config.BATCH_SIZE):\n",
    "            sample = memory[startInd:min(startInd+config.BATCH_SIZE,len(memory))]\n",
    "            states, policy_targets, value_targets = zip(*sample)\n",
    "\n",
    "            states, policy_targets, value_targets = np.array(states), np.array(policy_targets), np.array(value_targets)\n",
    "\n",
    "            states = torch.tensor(states, dtype=torch.float32).to(self.device)\n",
    "            policy_targets = torch.tensor(policy_targets, dtype = torch.float32).to(self.device)\n",
    "            value_targets = torch.tensor(value_targets,dtype = torch.float32).unsqueeze(1).to(self.device)\n",
    "\n",
    "            out_policy,out_value = self.model(states)\n",
    "\n",
    "            legal_mask = (policy_targets>0).float()\n",
    "            out_policy = out_policy * legal_mask\n",
    "            out_policy = out_policy / (out_policy.sum(dim=1,keepdim=True)+1e-10)\n",
    "\n",
    "            policy_loss = -torch.mean(\n",
    "                torch.sum(policy_targets * torch.log(out_policy+1e-8),dim=1)\n",
    "            )\n",
    "            value_loss = F.mse_loss(out_value, value_targets)\n",
    "\n",
    "            loss = policy_loss + value_loss\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(),5.0)\n",
    "            self.optimizer.step()\n",
    "    '''\n",
    "    def train(self, memory):\n",
    "      np.random.shuffle(memory)\n",
    "\n",
    "      total_loss = 0.0\n",
    "      total_policy = 0.0\n",
    "      total_value = 0.0\n",
    "      total_entropy = 0.0\n",
    "      batches = 0\n",
    "\n",
    "      for startInd in range(0, len(memory), config.BATCH_SIZE):\n",
    "          sample = memory[startInd:startInd + config.BATCH_SIZE]\n",
    "          states, policy_targets, value_targets = zip(*sample)\n",
    "\n",
    "          states = torch.tensor(np.array(states), dtype=torch.float32).to(self.device)\n",
    "          policy_targets = torch.tensor(np.array(policy_targets), dtype=torch.float32).to(self.device)\n",
    "          value_targets = torch.tensor(np.array(value_targets), dtype=torch.float32).unsqueeze(1).to(self.device)\n",
    "\n",
    "          out_policy, out_value = self.model(states)\n",
    "\n",
    "          legal_mask = (policy_targets > 0).float()\n",
    "          out_policy = out_policy * legal_mask\n",
    "          out_policy = out_policy / (out_policy.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "          policy_loss = -torch.mean(\n",
    "              torch.sum(policy_targets * torch.log(out_policy + 1e-8), dim=1)\n",
    "          )\n",
    "          value_loss = F.mse_loss(out_value, value_targets)\n",
    "\n",
    "          entropy = -torch.mean(\n",
    "              torch.sum(out_policy * torch.log(out_policy + 1e-8), dim=1)\n",
    "          )\n",
    "\n",
    "          loss = policy_loss + value_loss\n",
    "\n",
    "          self.optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          torch.nn.utils.clip_grad_norm_(self.model.parameters(), 5.0)\n",
    "          self.optimizer.step()\n",
    "\n",
    "          total_loss += loss.item()\n",
    "          total_policy += policy_loss.item()\n",
    "          total_value += value_loss.item()\n",
    "          total_entropy += entropy.item()\n",
    "          batches += 1\n",
    "\n",
    "      return {\n",
    "          \"loss\": total_loss / batches,\n",
    "          \"policy\": total_policy / batches,\n",
    "          \"value\": total_value / batches,\n",
    "          \"entropy\": total_entropy / batches,\n",
    "      }\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    def learn(self):\n",
    "        for iteration in range(config.TRAIN_ITERATIONS):\n",
    "            memory = []\n",
    "\n",
    "            self.model.eval()\n",
    "\n",
    "            # self play\n",
    "            for selfplay_iter in range(config.SELF_PLAY_ITERATIONS):\n",
    "                memory+=self.selfPlay()\n",
    "\n",
    "            # train\n",
    "            self.model.train()\n",
    "\n",
    "            for epoch in range(config.NUM_EPOCHES):\n",
    "                self.train(memory)\n",
    "\n",
    "            torch.save(self.model.state_dict(), f'model_{iteration}.pt')\n",
    "            torch.save(self.optimizer.state_dict(), f'optimizer_{iteration}.pt')\n",
    "    '''\n",
    "    def learn(self):\n",
    "      for iteration in range(config.TRAIN_ITERATIONS):\n",
    "          memory = []\n",
    "\n",
    "          self.model.eval()\n",
    "          for _ in range(config.SELF_PLAY_ITERATIONS):\n",
    "              memory += self.selfPlay()\n",
    "\n",
    "          self.model.train()\n",
    "\n",
    "          for epoch in range(config.NUM_EPOCHES):\n",
    "              stats = self.train(memory)\n",
    "              print(f'Iter {iteration} | Epoch {epoch}')\n",
    "              print(f'Loss {stats[\"loss\"]:.4f}')\n",
    "              print(f'Policy {stats[\"policy\"]:.4f}')\n",
    "              print(f'Value {stats[\"value\"]:.4f}')\n",
    "              print(f'Entropy {stats[\"entropy\"]:.4f}')\n",
    "\n",
    "\n",
    "          torch.save(self.model.state_dict(), f\"model_{iteration}.pt\")\n",
    "          torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aKR4wzz9y-I7"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    #filename=\"train.log\",\n",
    "    #filemode=\"a\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(message)s\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXu1zdS2yyGg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 | Epoch 0\n",
      "Loss 2.1161\n",
      "Policy 1.9194\n",
      "Value 0.1967\n",
      "Entropy 1.8889\n"
     ]
    }
   ],
   "source": [
    "model = ChessModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = config.LEARNING_RATE)\n",
    "\n",
    "alpha_jerry = AlphaZero(model, optimizer = optimizer)\n",
    "\n",
    "alpha_jerry.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABMa8z1WzXKh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "history_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
